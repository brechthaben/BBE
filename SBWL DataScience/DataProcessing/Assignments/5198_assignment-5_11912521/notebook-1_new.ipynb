{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3c527eeae484320ff379c8835a02686a",
     "grade": false,
     "grade_id": "cell-1c3320479f4749e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Creating the GeoID file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6cafab2e2a0caec0b47775cd216004fc",
     "grade": true,
     "grade_id": "cell-7df195f7e47ef8d0",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Notebook 1: Generate crimes_with_geoids.csv\n",
    "\n",
    "# Purpose: Loads raw crime data with coordinates and census tract centroids,\n",
    "#          performs a spatial join to match each crime to the nearest census tract,\n",
    "#          and saves the result (including crime details and the matched geoid)\n",
    "#          to './data/crimes_with_geoids.csv'.\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import warnings\n",
    "import os # For creating directory and joining paths\n",
    "\n",
    "print(\"--- Starting Notebook 1: Generating crimes_with_geoids.csv ---\")\n",
    "\n",
    "# --- Configuration ---\n",
    "# Define the directory where data is located and output will be saved\n",
    "DATA_DIR = \"./data\"\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "print(f\"Ensured data directory '{DATA_DIR}' exists.\")\n",
    "\n",
    "# Define input file paths\n",
    "# Assumes raw crime data is in JSON or JSON Lines format\n",
    "RAW_CRIME_JSON_PATH = os.path.join(DATA_DIR, \"crime_data.json\")\n",
    "# Assumes centroids are in a CSV file\n",
    "CENTROIDS_CSV_PATH = os.path.join(DATA_DIR, \"CA_tract_centroids_2020.csv.txt\")\n",
    "# Define the target output CSV file path\n",
    "OUTPUT_GEOID_CSV_PATH = os.path.join(DATA_DIR, \"crimes_with_geoids.csv\")\n",
    "\n",
    "# Fallback for original crime file name if needed\n",
    "ORIGINAL_CRIME_JSON_PATH = \"data_notebook-notebook-1_dataset2.json\"\n",
    "\n",
    "# --- STEP 0: Load Data ---\n",
    "print(\"Loading input data...\")\n",
    "try:\n",
    "    # Load crime data from JSON\n",
    "    actual_crime_path = RAW_CRIME_JSON_PATH\n",
    "    if not os.path.exists(actual_crime_path):\n",
    "         print(f\"Warning: '{actual_crime_path}' not found. Trying fallback '{ORIGINAL_CRIME_JSON_PATH}'...\")\n",
    "         if os.path.exists(ORIGINAL_CRIME_JSON_PATH):\n",
    "             actual_crime_path = ORIGINAL_CRIME_JSON_PATH\n",
    "         else:\n",
    "             raise FileNotFoundError(f\"Cannot find raw crime JSON file at '{RAW_CRIME_JSON_PATH}' or '{ORIGINAL_CRIME_JSON_PATH}'\")\n",
    "\n",
    "    with open(actual_crime_path, 'r') as f:\n",
    "        try:\n",
    "            crime_data_list = json.load(f)\n",
    "            print(f\"Loaded JSON data from {actual_crime_path}\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Reading {actual_crime_path} as JSON Lines format.\")\n",
    "            f.seek(0)\n",
    "            crime_data_list = [json.loads(line.strip()) for line in f if line.strip()]\n",
    "            print(f\"Loaded JSON Lines data from {actual_crime_path}\")\n",
    "\n",
    "    crime_df = pd.DataFrame(crime_data_list)\n",
    "    print(f\"Loaded {len(crime_df)} crime records.\")\n",
    "    # --- Make sure 'dr_no' exists and is suitable as a key ---\n",
    "    if 'dr_no' not in crime_df.columns:\n",
    "        print(\"ERROR: 'dr_no' column is missing from the raw crime data. This ID is required for merging later.\")\n",
    "        exit()\n",
    "    # Optional: Convert dr_no to string early if needed, though merge handles mixed types often\n",
    "    # crime_df['dr_no'] = crime_df['dr_no'].astype(str)\n",
    "\n",
    "\n",
    "    # Load centroids data\n",
    "    if not os.path.exists(CENTROIDS_CSV_PATH):\n",
    "        raise FileNotFoundError(f\"Cannot find centroids file at '{CENTROIDS_CSV_PATH}'\")\n",
    "    centroids_df = pd.read_csv(CENTROIDS_CSV_PATH)\n",
    "    print(f\"Loaded {len(centroids_df)} centroid records from {CENTROIDS_CSV_PATH}.\")\n",
    "\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading file: {e}. Make sure input files exist at the specified paths.\")\n",
    "    exit()\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error decoding JSON file: {e}. Check the JSON format.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during data loading: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- STEP 1: Prepare Centroids Data ---\n",
    "print(\"Preparing centroids data...\")\n",
    "try:\n",
    "    # Create the 11-digit GEOID\n",
    "    centroids_df['geoid'] = (\n",
    "        centroids_df['STATEFP'].astype(str).str.zfill(2) +\n",
    "        centroids_df['COUNTYFP'].astype(str).str.zfill(3) +\n",
    "        centroids_df['TRACTCE'].astype(str).str.zfill(6)\n",
    "    )\n",
    "    # Select only needed columns for the GeoDataFrame\n",
    "    centroids_prep_df = centroids_df[['geoid', 'LATITUDE', 'LONGITUDE']].copy()\n",
    "    print(\"Generated GEOIDs for centroids.\")\n",
    "except KeyError as e:\n",
    "    print(f\"Error preparing centroids: Missing expected column - {e}\")\n",
    "    print(f\"Available columns in centroids file: {centroids_df.columns.tolist()}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "     print(f\"An error occurred during centroid preparation: {e}\")\n",
    "     exit()\n",
    "\n",
    "# --- STEP 2: Prepare Crime Data (Coordinates) ---\n",
    "print(\"Preparing crime data coordinates...\")\n",
    "# Identify latitude and longitude columns (handle variations)\n",
    "lat_col = None\n",
    "lon_col = None\n",
    "if 'lat' in crime_df.columns:\n",
    "    lat_col = 'lat'\n",
    "elif 'latitude' in crime_df.columns:\n",
    "    lat_col = 'latitude'\n",
    "\n",
    "if 'lon' in crime_df.columns:\n",
    "    lon_col = 'lon'\n",
    "elif 'longitude' in crime_df.columns:\n",
    "    lon_col = 'longitude'\n",
    "\n",
    "if not lat_col or not lon_col:\n",
    "    print(f\"Error: Crime data is missing latitude (checked 'lat', 'latitude') or longitude (checked 'lon', 'longitude') columns.\")\n",
    "    print(f\"Available columns: {crime_df.columns.tolist()}\")\n",
    "    exit()\n",
    "else:\n",
    "    print(f\"Using '{lat_col}' for latitude and '{lon_col}' for longitude.\")\n",
    "\n",
    "# Clean and convert coordinates\n",
    "crime_df['lat_str'] = crime_df[lat_col].astype(str).str.replace('\"', '')\n",
    "crime_df['lon_str'] = crime_df[lon_col].astype(str).str.replace('\"', '')\n",
    "crime_df['lat_numeric'] = pd.to_numeric(crime_df['lat_str'], errors='coerce')\n",
    "crime_df['lon_numeric'] = pd.to_numeric(crime_df['lon_str'], errors='coerce')\n",
    "\n",
    "original_crime_count = len(crime_df)\n",
    "crime_df.dropna(subset=['lat_numeric', 'lon_numeric'], inplace=True)\n",
    "dropped_count = original_crime_count - len(crime_df)\n",
    "if dropped_count > 0:\n",
    "    print(f\"Dropped {dropped_count} crime records due to invalid/missing coordinates.\")\n",
    "\n",
    "if crime_df.empty:\n",
    "    print(\"Error: No valid crime records remaining after cleaning coordinates. Cannot proceed.\")\n",
    "    exit()\n",
    "print(\"Cleaned crime coordinates.\")\n",
    "\n",
    "# --- STEP 3: Convert to GeoDataFrames (Initial CRS) ---\n",
    "print(\"Converting to GeoDataFrames with initial CRS (EPSG:4326)...\")\n",
    "try:\n",
    "    crime_gdf = gpd.GeoDataFrame(\n",
    "        crime_df,\n",
    "        geometry=gpd.points_from_xy(crime_df.lon_numeric, crime_df.lat_numeric),\n",
    "        crs=\"EPSG:4326\"  # WGS84 - standard for lat/lon\n",
    "    )\n",
    "    print(\"Created crime GeoDataFrame.\")\n",
    "\n",
    "    centroids_gdf = gpd.GeoDataFrame(\n",
    "        centroids_prep_df,\n",
    "        geometry=gpd.points_from_xy(centroids_prep_df.LONGITUDE, centroids_prep_df.LATITUDE),\n",
    "        crs=\"EPSG:4326\" # WGS84\n",
    "    )\n",
    "    print(\"Created centroids GeoDataFrame.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating GeoDataFrames: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- STEP 4: Reproject to a Suitable Projected CRS ---\n",
    "# Using EPSG:3310 (NAD83 / California Albers) - good for statewide area/distance\n",
    "projected_crs = \"EPSG:3310\"\n",
    "print(f\"Reprojecting GeoDataFrames to {projected_crs} for accurate distance calculation...\")\n",
    "try:\n",
    "    crime_gdf_proj = crime_gdf.to_crs(projected_crs)\n",
    "    centroids_gdf_proj = centroids_gdf.to_crs(projected_crs)\n",
    "    print(\"Reprojection complete.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during reprojection: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- STEP 5: Perform Spatial Join (Nearest Neighbor) on Projected Data ---\n",
    "print(\"Performing spatial join (finding nearest centroid for each crime using projected data)...\")\n",
    "try:\n",
    "    # Keep only geometry from projected centroids for the join itself\n",
    "    centroids_join_data = centroids_gdf_proj[['geometry']]\n",
    "\n",
    "    # Perform the nearest neighbor join on the *projected* data\n",
    "    crimes_joined_proj = gpd.sjoin_nearest(\n",
    "        crime_gdf_proj,\n",
    "        centroids_join_data,\n",
    "        how='left',\n",
    "        distance_col=\"distance_meters\" # Distance will be in meters\n",
    "    )\n",
    "    print(\"sjoin_nearest completed.\")\n",
    "\n",
    "    # --- Merge the 'geoid' back using the index ---\n",
    "    # 'index_right' in crimes_joined_proj refers to the index of centroids_gdf_proj.\n",
    "    # The index of centroids_gdf_proj matches the index of the original centroids_gdf\n",
    "    # if we ensure the original index is clean (0, 1, 2...).\n",
    "    centroids_gdf = centroids_gdf.reset_index(drop=True) # Ensure default integer index\n",
    "\n",
    "    # Select only the 'geoid' from the original centroids GDF for merging\n",
    "    geoids_to_merge = centroids_gdf[['geoid']]\n",
    "\n",
    "    # Merge based on the index mapping from sjoin_nearest\n",
    "    crimes_with_geoids_final = crimes_joined_proj.merge(\n",
    "        geoids_to_merge,\n",
    "        left_on='index_right', # Index from the centroids GDF in the join\n",
    "        right_index=True,      # Use the actual index of geoids_to_merge\n",
    "        how='left'\n",
    "    )\n",
    "    print(\"Merged 'geoid' back to the joined crime data.\")\n",
    "    print(f\"Spatial join and geoid merge complete. Result has {len(crimes_with_geoids_final)} records.\")\n",
    "    # print(\"Columns after merge:\", crimes_with_geoids_final.columns.tolist()) # Debugging columns\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during spatial join or merging geoid: {e}\")\n",
    "    # Provide more context if available\n",
    "    if 'crimes_joined_proj' in locals():\n",
    "         print(f\"Columns in crimes_joined_proj before final merge: {crimes_joined_proj.columns.tolist()}\")\n",
    "    exit()\n",
    "\n",
    "# --- STEP 6: Clean Up and Save Output ---\n",
    "print(\"Cleaning up columns and saving results...\")\n",
    "\n",
    "# Define columns to keep for the output file.\n",
    "# We need the crime identifier ('dr_no') and the matched 'geoid'.\n",
    "# Include other potentially useful original crime columns.\n",
    "# Avoid geometry and intermediate coordinate columns.\n",
    "\n",
    "# Get original columns from the initial crime DataFrame\n",
    "original_cols = list(crime_df.columns)\n",
    "# Remove columns we definitely don't need in the final CSV for Notebook 2\n",
    "cols_to_remove_from_original = ['lat_str', 'lon_str', 'lat_numeric', 'lon_numeric', 'geometry']\n",
    "final_original_cols = [col for col in original_cols if col not in cols_to_remove_from_original]\n",
    "\n",
    "# Add the columns generated/merged by the spatial process\n",
    "added_cols_to_keep = ['geoid', 'distance_meters'] # Keep matched geoid and distance\n",
    "\n",
    "# Combine the lists, ensuring 'dr_no' and 'geoid' are present and removing duplicates\n",
    "cols_for_output = final_original_cols + added_cols_to_keep\n",
    "# Ensure critical columns are present\n",
    "if 'dr_no' not in cols_for_output:\n",
    "    cols_for_output.insert(0, 'dr_no') # Add if missing\n",
    "if 'geoid' not in cols_for_output:\n",
    "     cols_for_output.append('geoid') # Add if missing (shouldn't happen after merge)\n",
    "\n",
    "# Select only columns that actually exist in the final joined dataframe and remove duplicates\n",
    "final_output_columns = pd.Index([col for col in cols_for_output if col in crimes_with_geoids_final.columns]).unique().tolist()\n",
    "\n",
    "# Create the final dataframe with selected columns\n",
    "output_df = crimes_with_geoids_final[final_output_columns].copy()\n",
    "\n",
    "# Optional: Check for rows where geoid might be null after the merge (shouldn't happen with 'left' join unless centroids were missing)\n",
    "null_geoids = output_df['geoid'].isnull().sum()\n",
    "if null_geoids > 0:\n",
    "    print(f\"Warning: {null_geoids} records have a null 'geoid' after the join/merge process.\")\n",
    "\n",
    "# Save the result to the CSV file\n",
    "try:\n",
    "    output_df.to_csv(OUTPUT_GEOID_CSV_PATH, index=False)\n",
    "    print(f\"âœ… Successfully saved {len(output_df)} records to {OUTPUT_GEOID_CSV_PATH}\")\n",
    "    # Display first few rows of the output\n",
    "    print(\"\\nFirst 5 rows of the generated file:\")\n",
    "    print(output_df.head())\n",
    "    print(\"\\nColumns in the generated file:\")\n",
    "    print(output_df.columns.tolist())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error saving the output file '{OUTPUT_GEOID_CSV_PATH}': {e}\")\n",
    "\n",
    "print(\"\\n--- Finished Notebook 1 ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
